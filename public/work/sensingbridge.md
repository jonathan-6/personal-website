---
title: "SensingBridge"
subtitle: "Tuning AI with domain experts to analyze data"
platform: "Web AI platform"
timeline: "Feb 2017 - Feb 2022"
role: "Product Manager"
responsibilities: "Product strategy, User research, Feature prioritization, Technical roadmap, Go to market"
type: "case-study"
---

## Overview

Led product strategy for SensingBridge, an AI platform that helped organizations cut through information noise to identify emerging trends and opportunities. By processing millions of data points across research papers, patents, and news sources, we helped federal agencies and enterprises make faster, better-informed decisions about technology investments.

## Company

Deloitte is a global consulting firm that helps organizations solve complex challenges through innovative technology solutions. SensingBridge emerged as a key product line within Deloitte's federal practice, focused on using AI to analyze massive datasets and provide actionable insights for decision-makers. The platform represented a significant investment in making advanced data analysis accessible to non-technical users.

## Challenge

Through user research and stakeholder interviews, we identified several key challenges:

- Information was growing exponentially across academic papers, patents, news, and social media, making it impossible for teams to manually track relevant developments
- Different data sources had inconsistent formats and quality, making it difficult to extract meaningful patterns 
- Domain experts needed ways to encode their knowledge into the system to ensure relevant results
- Insights needed to be delivered in ways that non-technical users could understand and act upon


## Approach

## 1. Scalable data processing
- Prioritized development of real-time streaming capabilities using Apache Kafka to handle millions of daily updates
- Worked with engineering to define data quality standards and validation processes
- Created user feedback loops to continuously improve data relevance

## 2. Knowledge (feature) engineering
- Designed and facilitated workshops with domain experts to understand how they evaluate emerging trends
- Collaborated with technical teams to translate expert insights into flexible ontology systems
- Developed feature prioritization framework based on user needs and technical feasibility

## 3. Modern AI architecture
- Partnered with data science team to define success metrics for ML models
- Guided development of hybrid approach combining traditional ML with deep learning
- Led user testing to ensure AI insights were actionable and understood by users
- Established monitoring systems to track model performance and user adoption

## Results & Impact
- Processed over 100,000 data sources daily
- Cut research analysis time by 60%
- Contributed insights to 2017 Congressional paper on AI foundations
- Built reusable framework adopted across multiple domains
- Expanded to over a dozen accounts and created a profitable line of business

## Key Insights: Making AI work for end users

Building an AI platform in 2017 was challenging without the open source models today. Focusing on user experience and quality information helped us prioritize what to work on and releaved a few insights:

## 1. Expert knowledge is critical
Initially tried letting machine learning discover patterns independently. Through user research, we learned that combining AI with expert knowledge early and often through structured workshops dramatically improved our results. This helped us build features that found genuine insights rather than just statistical patterns.

## 2. Architecture for scale
Starting with Kafka for data ingestion proved crucial as we grew from thousands to millions of documents. This early decision let us scale smoothly while maintaining performance, avoiding the need for major rebuilds later.

## 3. Focus on action
The biggest lesson was that sophistication means nothing without adoption. We succeeded by:
- Making complex insights accessible through clear and useful visualizations
- Building transparent systems that explained their reasoning (i.e., what metrics were important for scoring)
- Creating intuitive interfaces for non-technical users
- Maintaining constant feedback loops with analysts and stakeholders

These insights shaped how we approach AI development: effective systems augment human expertise rather than trying to replace it. By combining machine scale with human insight, we helped organizations stay ahead of rapid change while focusing on what matters most to their objectives.